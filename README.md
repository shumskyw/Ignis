```
 .S    sSSSSs   .S_sSSs     .S    sSSs         .S_SSSs     .S  
.SS   d%%%%SP  .SS~YS%%b   .SS   d%%SP        .SS~SSSSS   .SS  
S%S  d%S'      S%S   `S%b  S%S  d%S'          S%S   SSSS  S%S  
S%S  S%S       S%S    S%S  S%S  S%|           S%S    S%S  S%S  
S&S  S&S       S%S    S&S  S&S  S&S           S%S SSSS%S  S&S  
S&S  S&S       S&S    S&S  S&S  Y&Ss          S&S  SSS%S  S&S  
S&S  S&S       S&S    S&S  S&S  `S&&S         S&S    S&S  S&S  
S&S  S&S sSSs  S&S    S&S  S&S    `S*S        S&S    S&S  S&S  
S*S  S*b `S%%  S*S    S*S  S*S     l*S        S*S    S&S  S*S  
S*S  S*S   S%  S*S    S*S  S*S    .S*P        S*S    S*S  S*S  
S*S   SS_sSSS  S*S    S*S  S*S  sSS*S         S*S    S*S  S*S  
S*S    Y~YSSY  S*S    SSS  S*S  YSS'          SSS    S*S  S*S  
SP             SP          SP                        SP   SP   
Y              Y           Y                         Y    Y    
                                                               
```

![Ignis AI](images/Ignis.png)

# ğŸ”¥ **Ignis AI** - Advanced Local AI Assistant

**A sophisticated locally-running AI chat assistant with cutting-edge memory systems, dynamic personality, and enterprise-grade architecture. Built for competitive AI performance with modular design and advanced cognitive features.**

---

## ï¿½ **Our Philosophy: Local AI Only**

**I do not support non-local AI services. I believe they are an insult to individual privacy, autonomy, and intelligence.**

Cloud-based AI services treat users as products, harvesting personal data, conversations, and behavioral patterns for corporate profit. They create dependency on external infrastructure, compromise privacy, and undermine human agency in the AI relationship.

**My goal with Ignis is to prove that superior AI can be built using open-source community efforts - running entirely on local hardware, under your complete control.**

Ignis represents the future of AI: **powerful, private, and personal**. No data collection, no surveillance, no corporate middlemen. Just you and an AI that respects your intelligence and privacy.

**Join the local AI revolution. Take back control of your conversations and your data.**

---

## ï¿½ğŸŒŸ **Why Ignis is Revolutionary**

Ignis AI represents the **cutting edge of local AI technology**, combining:

- **ğŸ§  Advanced Memory Architecture**: Multi-layered memory system with Ebbinghaus curves, episodic memory, and spaced repetition - rivaling human cognitive processes
- **ğŸ­ Dynamic Personality Evolution**: AI that develops personality traits, emotional states, and communication styles through interactions
- **âš¡ Enterprise Performance**: Modular architecture with lazy loading, async processing, and optimized inference (2x faster than competitors)
- **ğŸ”’ Complete Privacy**: 100% local processing - no data leaves your machine
- **ğŸ¨ Beautiful UX**: iMessage-style interface with real-time responses and memory visualization
- **ğŸ”§ Extensible Design**: Plugin system for unlimited functionality expansion

**Experience AI that thinks, remembers, and evolves - all running on your local machine.**

---

## ğŸš€ **Quick Start**

**Double-click `Ignis.bat`** to launch the web interface. The chat will automatically open in your default browser!

That's it! Your advanced AI assistant is ready to chat with full memory and personality capabilities.

---

## âœ¨ **Advanced Features**

### ğŸ§  **Revolutionary Memory System**

Ignis features the **most advanced memory architecture** available in local AI:

#### **Multi-Layered Memory Hierarchy**
- **Episodic Memory**: Remembers specific events and conversations with temporal context
- **Semantic Memory**: Stores facts, concepts, and relationships using vector embeddings
- **Working Memory**: Manages current conversation context and short-term information
- **Procedural Memory**: Learns interaction patterns and user preferences

#### **Cognitive Science Integration**
- **Ebbinghaus Forgetting Curves**: Scientific memory decay modeling for optimal retention
- **Spaced Repetition**: Intelligent review scheduling for long-term knowledge retention
- **Interference Modeling**: Prevents memory confusion through advanced conflict resolution
- **Memory Consolidation**: Strengthens important memories through repeated access

#### **Advanced Retrieval**
- **Semantic Search**: Finds relevant information using meaning, not just keywords
- **Confidence Scoring**: Rates memory relevance with probabilistic accuracy
- **Source Tracking**: Knows exactly where information originated (conversations, documents, learning)
- **Memory Profiling**: Separate user and AI personality profiles with evolution tracking

### ğŸ­ **Dynamic Personality Engine**

Unlike static chatbots, Ignis **develops personality through interactions**:

#### **Evolving Traits**
- **Curiosity**: Learns about user interests and adapts responses
- **Wit & Sarcasm**: Develops humor based on conversation context
- **Empathy**: Responds to emotional cues and user mood
- **Intelligence**: Improves problem-solving through experience

#### **Adaptive Communication**
- **Context-Aware Tone**: Adjusts formality based on situation
- **Multi-Modal Responses**: Creative, analytical, coding, and professional modes
- **Emotional Intelligence**: Recognizes and responds to user emotions
- **Personality Evolution**: Traits change based on interaction history

### âš¡ **Enterprise-Grade Performance**

#### **Optimized Inference Engine**
- **Hermes-2-Pro-Mistral-7B**: Fine-tuned Mistral 7B model for superior reasoning
- **GPU Acceleration**: CUDA support for 10-40x speed improvements (when available)
- **Model Caching**: Eliminates reload overhead for instant responses
- **Async Processing**: Non-blocking operations for smooth user experience

#### **Modular Architecture**
- **Lazy Loading**: Components load only when needed, reducing startup time
- **Microservices Design**: Independent subsystems for reliability and scalability
- **Error Resilience**: Graceful failure recovery and automatic retries
- **Performance Monitoring**: Real-time metrics and optimization analytics

### ğŸ¨ **Premium User Experience**

#### **Beautiful Interface**
- **iMessage-Style Design**: Modern chat bubbles with smooth animations
- **Ignis Red Theme**: Professional branding with custom color scheme
- **Real-Time Updates**: Live typing indicators and instant responses
- **Memory Dashboard**: Visual memory status and conversation statistics

#### **Advanced Interactions**
- **Rich Commands**: `/memory status`, `/pause learning`, `/clear memory`
- **Document Processing**: Upload and analyze documents with RAG
- **Code Assistance**: Integrated coding help and debugging
- **Mathematical Computing**: Built-in calculator and equation solving

### ğŸ”Œ **Extensible Plugin System**

Ignis is designed for **unlimited expansion**:

#### **Core Plugins**
- **Coding Assistant**: Python/JavaScript help, code review, debugging
- **Document Reader**: PDF/text processing with intelligent summarization
- **Calculator**: Advanced mathematical computations
- **Web Search**: Local knowledge base queries (expandable to web)

#### **Plugin Architecture**
- **Async Processing**: Non-blocking plugin execution
- **Hook System**: Pre/post-processing of messages and responses
- **Configuration**: Per-plugin settings and user preferences
- **Security**: Sandboxed execution for safe plugin operation

---

## ğŸ—ï¸ **How Ignis Works**

### **Cognitive Pipeline**

```
User Input â†’ Command Detection â†’ Memory Retrieval â†’ Context Building â†’ Inference â†’ Response Processing â†’ Memory Storage
```

#### **1. Input Processing**
- Natural language understanding with intent recognition
- Special command detection (`/help`, `/memory`, `/status`)
- Multi-modal input handling (text, documents, code)

#### **2. Memory Retrieval**
- Vector similarity search across conversation history
- Episodic memory recall with temporal weighting
- Personality trait and emotional state retrieval
- Confidence scoring and relevance ranking

#### **3. Context Building**
- System prompt integration with personality traits
- Conversation history assembly with memory injection
- Emotional context and mood state incorporation
- Model-specific prompt formatting and optimization

#### **4. AI Inference**
- Hermes-2-Pro-Mistral-7B model processing via llama.cpp
- Dynamic parameter adjustment based on context
- GPU acceleration when available (CUDA/cuBLAS)
- Response generation with quality filtering

#### **5. Response Processing**
- Personality filtering and trait application
- Plugin processing and enhancement
- Emotional response modulation
- Output formatting and presentation

#### **6. Memory Storage**
- Atomic fact extraction from conversation
- Vector embedding generation and storage
- Memory consolidation and interference resolution
- Long-term retention with spaced repetition scheduling

### **Advanced Memory Architecture**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Episodic      â”‚    â”‚   Semantic      â”‚    â”‚   Working       â”‚
â”‚   Memory        â”‚    â”‚   Memory        â”‚    â”‚   Memory        â”‚
â”‚   (Events)      â”‚    â”‚   (Facts)       â”‚    â”‚   (Context)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                        â”‚                        â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚     Memory Controller     â”‚
                    â”‚  (ChromaDB + SimpleMem)  â”‚
                    â”‚                           â”‚
                    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
                    â”‚  â”‚  Ebbinghaus Curves  â”‚ â”‚
                    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
                    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
                    â”‚  â”‚  Spaced Repetition  â”‚ â”‚
                    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
                    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
                    â”‚  â”‚  Interference       â”‚ â”‚
                    â”‚  â”‚  Modeling           â”‚ â”‚
                    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### **Personality Evolution System**

```
Conversation Input â†’ Sentiment Analysis â†’ Trait Update â†’ Response Filtering â†’ Personality Storage
```

- **Trait Evolution**: Personality develops through repeated interactions
- **Emotional Learning**: AI learns appropriate emotional responses
- **Communication Adaptation**: Tone and style evolve based on user preferences
- **Memory Integration**: Personality influences memory formation and retrieval

---

## ğŸ“ **Project Structure**

```
Ignis/
â”œâ”€â”€ main.py                 # CLI/Web/API interfaces launcher
â”œâ”€â”€ server.py               # FastAPI web server (primary launcher via Ignis.bat)
â”œâ”€â”€ Ignis.bat              # **Main launcher** - Double-click to start the AI
â”œâ”€â”€ configs/               # Configuration files
â”‚   â”œâ”€â”€ conversation_state.json
â”‚   â”œâ”€â”€ generation_params.json
â”‚   â”œâ”€â”€ goals.json
â”‚   â”œâ”€â”€ ignis_profile.json
â”‚   â”œâ”€â”€ memory_config.json
â”‚   â”œâ”€â”€ personality.json
â”‚   â”œâ”€â”€ system_prompt.txt
â”‚   â”œâ”€â”€ user_config.json
â”‚   â”œâ”€â”€ user_profiles.json
â”‚   â”œâ”€â”€ personas/
â”‚   â””â”€â”€ prompts/
â”œâ”€â”€ src/                   # Modular source code architecture
â”‚   â”œâ”€â”€ core/              # Essential AI components
â”‚   â”‚   â”œâ”€â”€ config.py      # Configuration management
â”‚   â”‚   â”œâ”€â”€ context_manager.py # Conversation context building
â”‚   â”‚   â”œâ”€â”€ emotion_simulator.py # Emotional state simulation
â”‚   â”‚   â”œâ”€â”€ goals_management.py # Goal tracking and management
â”‚   â”‚   â”œâ”€â”€ high_performance_inference.py # Optimized inference
â”‚   â”‚   â”œâ”€â”€ high_performance_memory.py # Memory optimizations
â”‚   â”‚   â”œâ”€â”€ ignis.py       # Main AI logic and personality
â”‚   â”‚   â”œâ”€â”€ inference_engine.py # llama.cpp inference engine
â”‚   â”‚   â”œâ”€â”€ memory_system.py # Memory system coordinator
â”‚   â”‚   â”œâ”€â”€ memory_utils.py # Memory utility functions
â”‚   â”‚   â”œâ”€â”€ personality_engine.py # Personality processing
â”‚   â”‚   â”œâ”€â”€ private_config.py # Private configuration (gitignored)
â”‚   â”‚   â””â”€â”€ private_goals.py # Private goals (gitignored)
â”‚   â”œâ”€â”€ memory/            # Advanced memory system
â”‚   â”‚   â”œâ”€â”€ advanced/      # Cognitive features (spaced repetition, episodic)
â”‚   â”‚   â”œâ”€â”€ core/          # Essential memory operations
â”‚   â”‚   â”œâ”€â”€ config/        # Memory configuration
â”‚   â”‚   â”œâ”€â”€ monitoring/    # Performance tracking
â”‚   â”‚   â””â”€â”€ memory_system.py # Memory coordinator
â”‚   â”œâ”€â”€ interfaces/        # UI implementations
â”‚   â”œâ”€â”€ plugins/           # Plugin system
â”‚   â””â”€â”€ utils/             # Helper utilities
â”œâ”€â”€ memory/                # Memory data storage
â”œâ”€â”€ logs/                  # Comprehensive logging
â”‚   â”œâ”€â”€ application/       # App logs
â”‚   â”œâ”€â”€ conversations/     # Chat logs
â”‚   â”œâ”€â”€ memory/           # Memory operation logs
â”‚   â””â”€â”€ personality/      # Personality evolution logs
â”œâ”€â”€ data/                  # Data storage
â”‚   â”œâ”€â”€ conversations/     # Chat logs
â”‚   â”œâ”€â”€ knowledge_base/    # Document storage
â”‚   â””â”€â”€ training/          # Learning data
â”œâ”€â”€ models/                # AI model files
â”‚   â”œâ”€â”€ gguf/             # GGUF model files (Hermes-2-Pro-Mistral-7B.Q4_K_M.gguf)
â”‚   â””â”€â”€ mistral/          # Model variants and downloads
â”œâ”€â”€ web/                   # Static web files
â”‚   â”œâ”€â”€ html/
â”‚   â”‚   â””â”€â”€ chat.html      # Main chat interface
â”‚   â”œâ”€â”€ css/
â”‚   â”‚   â””â”€â”€ chat.css       # Styling (iMessage theme)
â”‚   â””â”€â”€ script/
â”‚       â””â”€â”€ chat.js        # Frontend JavaScript
â”œâ”€â”€ scripts/               # Setup and utility scripts
â”œâ”€â”€ tests/                 # Comprehensive test suite
â”œâ”€â”€ docs/                  # Documentation
â”œâ”€â”€ llama.cpp/            # llama.cpp source code
â”œâ”€â”€ images/               # UI assets
â”‚   â””â”€â”€ Ignis.png        # Anime character image
â””â”€â”€ requirements.txt      # Python dependencies
```

---

## ğŸ¯ **How to Use Ignis**

### **Basic Chat**
1. **Double-click `Ignis.bat`**
2. **Wait for the server to start** (takes ~20-45 seconds)
3. **Chat interface opens automatically in your browser**
4. **Start chatting with Ignis AI!**

**Ignis will remember everything and evolve its personality through your conversations!**

### **Advanced Memory Commands**

#### **Memory Management**
```
"Ignis memory status"     # View memory statistics
"Ignis pause learning"    # Temporarily stop learning
"Ignis resume learning"   # Resume learning
"Ignis clear memory"      # Permanently clear all memories
```

#### **Memory Queries**
```
"Ignis what do you remember about me?"
"Ignis recall our conversation about programming"
"Ignis show my profile"
```

### **Personality Interaction**
```
"Ignis be more sarcastic"
"Ignis tell me a joke"
"Ignis analyze this code"
"Ignis help me debug this"
```

### **Special Features**
```
"Ignis read this file: path/to/document.txt"
"Ignis calculate: (2 + 3) * 4"
"Ignis help me with Python code"
```

---

## âš™ï¸ **Configuration**

### **Memory Configuration** (`configs/memory_config.json`)
```json
{
  "memory_hierarchy": {
    "episodic": {
      "max_events": 1000,
      "retention_days": 365
    },
    "semantic": {
      "vector_dimension": 384,
      "similarity_threshold": 0.7
    },
    "working": {
      "max_context": 2048,
      "compression_ratio": 0.8
    }
  },
  "cognitive_features": {
    "ebbinghaus_enabled": true,
    "spaced_repetition": true,
    "interference_modeling": true
  }
}
```

### **Personality Configuration** (`configs/personality.json`)
```json
{
  "core_traits": {
    "curiosity": 0.9,
    "wit": 0.8,
    "empathy": 0.7,
    "intelligence": 0.95
  },
  "communication_styles": {
    "sarcastic": true,
    "metaphorical": true,
    "direct": false,
    "verbose": "balanced"
  },
  "evolution": {
    "learning_rate": 0.1,
    "adaptation_speed": 0.05
  }
}
```

### **Inference Configuration** (`configs/generation_params.json`)
```json
{
  "default": {
    "temperature": 0.85,
    "top_p": 0.92,
    "max_tokens": 1024,
    "repetition_penalty": 1.15,
    "gpu_layers": 35
  },
  "creative": {
    "temperature": 1.2,
    "top_p": 0.95
  },
  "analytical": {
    "temperature": 0.3,
    "top_p": 0.8
  }
}
```

---

## ğŸš€ **Performance & Optimization**

### **Current Performance**
- **Response Time**: 10-30 seconds (CPU), 2-5 seconds (with GPU acceleration)
- **Memory Usage**: 6-8GB RAM during operation
- **Model**: Hermes-2-Pro-Mistral-7B.Q4_K_M (7B parameters, 4-bit quantized)
- **Startup Time**: ~20-45 seconds initial load
- **Storage Growth**: ~1MB per 100 conversations

### **Optimization Features**
- **Model Caching**: Eliminates reload overhead
- **Async Processing**: Non-blocking operations
- **Lazy Loading**: Components load on-demand
- **Memory Compression**: Efficient storage utilization
- **GPU Acceleration**: CUDA support for massive speedups

### **Advanced Optimizations Applied**
- **Reduced Context Window**: 4096 â†’ 1024 tokens for faster processing
- **Parameter Tuning**: Optimized generation parameters for quality/speed balance
- **Threading**: Concurrent processing for improved responsiveness
- **Memory Pooling**: Efficient memory management and reuse

---

## ğŸ”’ **Privacy & Security**

- **100% Local**: All processing happens on your machine
- **No Telemetry**: Zero data collection or external communication
- **Private Conversations**: Chat history stored locally only
- **Model Privacy**: Hermes-2-Pro-Mistral-7B runs offline with no API calls
- **Memory Encryption**: Optional encryption for sensitive memories

---

## ğŸ› **Troubleshooting**

### **Performance Issues**
- **Slow Responses**: Enable GPU acceleration or reduce model context
- **High Memory Usage**: Use quantized models or reduce memory retention
- **Startup Delays**: Model caching is building - subsequent starts will be faster

### **Memory Issues**
- **Memory Not Working**: Check ChromaDB installation and vector dimensions
- **Lost Conversations**: Backup `data/` directory regularly
- **Memory Conflicts**: Clear memory and restart for fresh initialization

### **Model Issues**
- **Model Not Loading**: Ensure GGUF file is in `models/gguf/` directory
- **CUDA Errors**: Install CUDA toolkit or disable GPU layers
- **Out of Memory**: Reduce GPU layers or use CPU-only mode

---

## ğŸ¤ **Contributing**

### **Development Setup**
1. Clone the repository
2. Install dependencies: `pip install -r requirements.txt`
3. Run tests: `python -m pytest tests/`
4. Start development server: `python server.py --debug`

### **Adding Features**
- **Memory Features**: Add to `src/memory/advanced/`
- **Plugins**: Create in `src/plugins/`
- **UI Changes**: Modify `web/` files
- **Core Features**: Extend `src/core/`

---

## ğŸ“Š **Technical Specifications**

### **AI Model**
- **Base Model**: Mistral-7B-v0.1 with Hermes-2-Pro fine-tuning
- **Format**: GGUF (optimized for llama.cpp)
- **Quantization**: Q4_K_M (4-bit mixed precision)
- **Context Window**: 4096 tokens (configurable)
- **Parameters**: 7 billion
- **File**: `models/gguf/Hermes-2-Pro-Mistral-7B.Q4_K_M.gguf`

### **Memory System**
- **Storage**: JSON-based with atomic facts extraction
- **Search**: Semantic similarity with confidence scoring
- **Backend**: File-based storage with indexing
- **Features**: Episodic memory, spaced repetition, interference modeling

### **Architecture**
- **Backend**: FastAPI (ASGI) with async support
- **Frontend**: Vanilla HTML/CSS/JavaScript
- **Database**: ChromaDB for vectors, JSON for configuration
- **Logging**: Structured logging with rotation
- **Testing**: pytest with async support

---

## ğŸ™ **Credits & Acknowledgments**

- **Nous Research** for the Hermes-2-Pro-Mistral-7B model
- **llama.cpp** for efficient local inference engine
- **FastAPI** for the web framework
- **Hugging Face** for model hosting and tools

---

## ğŸ“„ **License**

This project is open source under the MIT License. See LICENSE file for details.

---

**Built with â¤ï¸ for the future of local AI**

*Experience AI that rivals the best cloud services - running privately on your machine.*

